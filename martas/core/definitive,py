#!/usr/bin/env python
# coding=utf-8

"""
Definitve analysis methods

| class   |      method     |  version |  tested  |              comment             | manual | *used by |
| ------- |  -------------  |  ------- |  ------- |  ------------------------------- | ------ | ---------- |
|         |  variocorr      |  2.0.0   |      - |                               | -       | mysql,ow,arduino libs |
|         |  scalarcorr     |  2.0.0   |      - |                                  | -      | archive  |

"""

import unittest
from magpy.stream import *
from magpy.core import methods

from martas.core import methods as mm
from martas.app import basevalue

"""
import magpy.absolutes as di
from magpy.core import plot as mp
from magpy.core import database
from magpy.opt import cred as mpcred

from martas.version import __version__

from dateutil.parser import parse
from shutil import copyfile

import itertools
import getopt
import pwd
import socket
import sys  # for sys.version_info()

from martas.core.methods import martaslog as ml
"""


def variocorr(runmode, config=None, startmonth=0, endmonth=12, skipsec=False, debug=False):
    """
    DEFININTION:
        calculate variometer files with baseline and flagging information
    PARAMETER:
        runmode:  firstrun  -> xxx
                  secondrun ->
                  thidrun   ->
        skipsec: do not write second data files

    """
    if not config:
        config = {}
        print ("No configuartion data existing")
        return

    sourcepath = os.path.join(config.get('base'), 'archive', config.get('obscode'))
    db = config.get('primaryDB')
    outpath = config.get('outpath',"/tmp")

    if debug:
        print ("##########################################################")
        print (" ----------------------------------------------------------------------- ")
        print (" ----------------  Creating minute filtered variodata  ----------------- ")
        print (" -------------------  apply constant/true baseline       -------------------- ")
        print (" ----------------------------------------------------------------------- ")

    def update_rot(stream,year,alpha,beta=None):
            exist = stream.header.get('DataRotationAlpha','')
            if not exist == '':
                val = '{},{}_{}'.format(exist,year,alpha)
            else:
                val = '{}_{}'.format(year,alpha)
            stream.header['DataRotationAlpha'] = val
            if beta:
                exist = stream.header.get('DataRotationBeta','')
                if not exist == '':
                    val = '{},{}_{}'.format(exist,year,beta)
                else:
                    val = '{}_{}'.format(year,beta)
                stream.header['DataRotationBeta'] = val

    vainstlist = config.get('vainstlist',[])
    year = config.get('year')
    testdate = config.get('testdate',None)
    scinstlist = config.get('scinstlist')
    prf = scinstlist[0]
    rotangledict = {}

    #### If a testdate is provided (single day)
    tdate = None
    if testdate:
        #extract date and month
        tdate = datetime.strptime(testdate,"%Y-%m-%d")
        if not tdate.year == year:
            print ("Year not fitting - ignoring testdate")
            tdate = None
        else:
            startmonth = tdate.month-1
            endmonth = tdate.month

    #### READ MONTHLY ONE SECOND DATA
    for i in range(startmonth,endmonth):   # 0,12
        month = str(i+1).zfill(2)
        nextmonth = str(i+2).zfill(2)
        nextyear = year
        if nextmonth == '13':
            nextyear = year+1
            nextmonth = '01'
        for absidx,inst in enumerate(vainstlist):
            print ("-------------------------------------")
            print ("Running analysis for {}".format(inst))
            print ("-------------------------------------")
            print ("Using Variometer data from path: {}".format(os.path.join(sourcepath, inst[:-5], inst, '*')))

            if not tdate:
                dstarttime=datetime.strptime(str(year)+'-'+month+'-01',"%Y-%m-%d")
                dendtime=datetime.strptime(str(nextyear)+'-'+nextmonth+'-01',"%Y-%m-%d")
            else:
                dstarttime=tdate
                dendtime=tdate+timedelta(days=1)
            print ("Dealing with data between {} and {}".format(dstarttime,dendtime))

            try:
                va = read(os.path.join(sourcepath, inst[:-5], inst, '*'),starttime=dstarttime,endtime=dendtime)
                # raw data
            except:
                va = DataStream()

            if va.length()[0] > 1:

                # 1) get header from db
                # ---------------------
                va.header = db.fields_to_dict(inst)
                if va.header.get('SensorID','') == '':
                    va.header['SensorID'] = inst[:-5]
                # 2) Remove duplicates
                print ("Removing duplicates")
                bef = va.length()[0]
                va = va.removeduplicates()
                aft = va.length()[0]
                print (" -> dropped {} duplicate values".format(bef-aft))
                # 3) Fill gaps with nan
                print ("Filling gaps")
                va = va.get_gaps()
                # 4) flag data
                # ---------------------
                #  --a. add flaglist from db
                print ("Flagging")
                flaglist = db.flags_from_db(va.header['SensorID'], begin=dstarttime, end=dendtime)
                print("Loaded {} flags from DB for this time range".format(len(flaglist)))
                #  --b. add flaglist from file
                flagfile = os.path.join(outpath,'magpy',inst[:-5]+'_flags.json')
                fileflaglist = flagging.load(flagfile, sensorid=va.header['SensorID'])
                print("Loaded {} flags from file in this time range".format(len(fileflaglist)))
                if len(flaglist) > 0 and len(fileflaglist) > 0:
                    flaglist = flaglist.join(fileflaglist)
                elif not len(flaglist) > 0:
                    flaglist = fileflaglist
                print ("Found a sum of {} flags".format(len(flaglist)))
                print ("Applying {} flags".format(len(flaglist)))
                va.header["DataFlags"] = flaglist
                #va = flaglist.apply_flags(va, mode='drop')
                ## Checkpoint
                #mp.plot(va,variables=['x','y','z'],annotate=True)
                # 5) apply compensation
                # ---------------------
                print("Applying compensation values")
                va = va.compensation(skipdelta=True)
                # 6) apply delta values
                # ---------------------
                print("Applying delta values")
                va = va.apply_deltas()
                # 7) determine and apply rotation
                # ---------------------
                print("Applying rotation values")   ### should be done after removal of flags....
                rotstring = va.header.get('DataRotationAlpha','')
                rotdict = string2dict(rotstring,typ='oldlist')
                print ("Existing rotation angle alpha for {}: {}".format(str(year), rotdict.get(str(year),'')))
                betastring = va.header.get('DataRotationBeta','')
                betadict = string2dict(betastring,typ='oldlist')
                print ("Existing rotation angle beta for {}: {}".format(str(year), betadict.get(str(year),'')))
                if runmode == 'firstrun' or rotdict.get(str(year),0) == 0:
                            print ("Initial run: No rotation value determined so far -- doing that now")
                            print ("Need to drop flagged data now...")
                            va = va.remove_flagged()
                            print ("Getting rotation angle - please note... correct beta determination requires DI data for reference Inclination")
                            alpha, beta = va.get_rotation(debug=True)
                            rotangle = alpha
                            print ("Determined rotation angle alpha for {}: {}".format(va.header.get('SensorID'),rotangle))
                            print ("!!! Please note: These  new rotation angles are not yet applied.")
                            print ("!!! Please note: They are used for secondrun onwards.")
                            print ("!!! Please note: update DB with correct rotation angles. ")
                else:
                            rotangle = float(rotdict.get(str(year),'0.0'))
                            beta = float(betadict.get(str(year),'0.0'))
                            print("Advanced runs (after firstrun): Using rotation angles alpha= {} and beta={}".format(rotangle, beta))
                            # Only apply full year values - as baseline calc uses them as well
                            va = va.rotation(alpha=rotangle, beta=beta)
                orgva = va.copy()

                # 8) calc baseline
                # ---------------------
                # requirement: base value data has been cleaned up
                basename = ""
                if runmode in  ['firstrun']:
                    scalar = prf[:-5]
                    #basename = 'BLVcomp_'+inst[:-5]+'_'+scalar+'_A2_'+str(year)+'.txt'
                    basename = 'BLV_'+inst[:-5]+'_'+scalar+'_A2_'+str(year)+'.txt' ### NEW
                elif runmode in ['secondrun','thirdrun']:
                    scalar = prf[:-5]
                    basename = 'BLVcomp_'+inst[:-5]+'_'+scalar+'_A2_'+str(year)+'_'+runmode+'.txt'

                print ("Applying baseline file: {}".format(basename))
                if os.path.isfile(os.path.join(outpath,'magpy',basename)):
                    absr = read(os.path.join(outpath,'magpy',basename))
                    flaglist = absr.header.get("DataFlags")
                    if flaglist:
                        absr = flaglist.apply_flags(absr, mode='drop')
                    print ("Basevalue SensorID:", absr.header.get('DataID'))
                    print (" -- Dropping flags from DB")
                    blvflaglist = db.flags_from_db(absr.header.get('DataID'))
                    print ("   -> {} flags".format(len(blvflaglist)))
                    if flaglist:
                        absr = flaglist.apply_flags(absr, mode='drop')
                    print (" -- Dropping flags from File")
                    flaglist = flagging.load( config.get('diflagfile'), sensorid=absr.header.get('DataID'))
                    print ("   -> {} flags".format(len(flaglist)))
                    if flaglist:
                        absr = flaglist.apply_flags(absr, mode='drop')

                    # Checkpoint
                    #mp.plot(absr)
                    if runmode == 'firstrun':
                        print ("Dropping flagged data")
                        va = flaglist.apply_flags(va, mode='drop')
                        va = va.get_gaps()
                        print ("Filtering data")
                        va = va.filter(missingdata='mean')
                        # Checkpoint
                        #mp.plot(va,variables=['x','y','z'])
                        va = va.get_gaps()
                        print ("Length after gaps removal (min):", va.length()[0])
                        #### GET CONSTANT BASEVALUE
                        print ("Trimming basevalue file to get mean value")
                        bl = 'cbmin'
                        if str(year) == '2021' and inst == 'LEMI036_2_0001_0002' and i >= 6:
                            absr = absr.trim(starttime=str(year)+'-07-08',endtime=str(year+1)+'-01-01')
                        elif str(year) == '2021' and inst == 'LEMI036_2_0001_0002' and i < 6:
                            print ("....here")
                            absr = absr.trim(starttime=str(year)+'-01-01',endtime=str(year+1)+'-06-30')
                        else:
                            absr = absr.trim(starttime=str(year)+'-01-01',endtime=str(year+1)+'-01-01')
                        print (" -> remaining DI measurements: ", absr.length())
                        absr = absr._drop_nans('dx')
                        bh, bhstd = absr.mean('dx',meanfunction='median',std=True)
                        bd, bdstd = absr.mean('dy',meanfunction='median',std=True)
                        bz, bzstd = absr.mean('dz',meanfunction='median',std=True)

                        print (" Basevalues for {}:".format(year))
                        print (" Delta H = {a} +/- {b}".format(a=bh, b=bhstd))
                        print (" Delta D = {a} +/- {b}".format(a=bd, b=bdstd))
                        print (" Delta Z = {a} +/- {b}".format(a=bz, b=bzstd))

                        print ("Performing constant basevalue correction")
                        va = va.simplebasevalue2stream([bh,bd,bz])
                    else:
                        bl = 'blmin_{}'.format(runmode)
                        ### TODO the steps below require that basevalues are already calculated with a corrected data set
                        print("Determining baseline")
                        starttime = str(year-1)+'-12-01'
                        endtime = str(year+1)+'-02-01'
                        funclist = []
                        # What about a baseline jump i.e. two or more baseline fits ?
                        # get timeranges and baseline fit parameters from database
                        print (" -> getting baseline fit parameter from database")
                        ett = methods.testtime(endtime)

                        while ett > methods.testtime(starttime):
                            baselst = db.get_baseline(va.header.get('SensorID',''),date=ett)
                            if methods.testtime(baselst[1][0]) < methods.testtime(starttime):
                                 stt = starttime
                            else:
                                 stt = datetime.strftime(methods.testtime(baselst[1][0]),"%Y-%m-%d")
                            if methods.testtime(baselst[2][0]) > methods.testtime(endtime):
                                 ett = endtime
                            else:
                                 ett = datetime.strftime(methods.testtime(baselst[2][0]),"%Y-%m-%d")
                            print (" => Adding fit with typ {}, knots {}, degree {} between {} and {}".format(baselst[4][0], float(baselst[6][0]), float(baselst[5][0]),stt, ett))
                            try:
                                funclist.append(va.baseline(absr, extradays=0, fitfunc=baselst[4][0], knotstep=float(baselst[6][0]), fitdegree=float(baselst[5][0]),startabs=stt,endabs=ett))
                                print (" => Done")
                            except:
                                print (" => Failed to add baseline parameters")
                            ett = methods.testtime(baselst[1][0])-timedelta(days=1)

                    print ("AbsInfo in stream: {}".format(va.header.get('DataAbsInfo')))
                    if runmode in ['secondrun','thirdrun'] and not skipsec: # Save high res data when finishing
                        hva = va.copy()
                        print ("Updating rotation information...")
                        update_rot(hva,year,rotangle, beta) ## new 2017
                        #hva = hva.resample(keys=['x','y','z','t1','t2','var2','flag','comment'], period=1)
                        print ("Write monthly high resolution file with full info")
                        fname = '{}_vario_sec_{}_'.format(inst,runmode)
                        hva.write(os.path.join(outpath,'magpy'),filenamebegins=fname,dateformat='%Y%m',coverage='month',mode='replace',format_type='PYCDF')
                    print("remove, gaps and filter:", va.length()[0])
                    va = va.remove_flagged()
                    #print(va.length())
                    va = va.get_gaps()
                    #print(va.length())
                    va = va.filter()
                    va = va.get_gaps()

                    print ("Absolute data has now been loaded and applied - determining true beta now")
                    print ("Get reference Inclination for the specific month:")
                    redabsr = absr.trim(starttime=dstarttime,endtime=dendtime)
                    meanI = redabsr.mean('x')
                    print ("Mean inclination in abs data = {}".format(meanI))
                    alpha, beta = orgva.get_rotation(referenceI=meanI, debug=True)

                    if rotangledict.get(inst,[]) == []:
                        rotangledict[inst] = [[alpha,beta]]
                    else:
                        rotangledict[inst].append([alpha,beta])

                    if va.length()[0] > 0:
                        va.write(os.path.join(outpath,'magpy'), filenamebegins=inst+'_vario_'+bl+'_'+str(year),dateformat='%Y',mode='replace',coverage='all',format_type='PYCDF')
                else:
                    print (" !!! Basevalue file not existing")


    print ("----------------------------------------------------------")
    print ("Variometer data analyzed and filtered for months {} until first of {}".format(startmonth+1, endmonth+1))
    print ("Runmode: {}".format(runmode))
    print ("Rotation angles: {}".format(rotangledict))
    for inst in vainstlist:
        print ("Extracting rotation for variometer {}".format(inst))
        rotanglelist = rotangledict.get(inst,[])
        if len(rotanglelist) == 2:
            try:
                meanrotangle = np.nanmean(rotanglelist,axis=0)
            except:
                meanrotangle = np.mean(rotanglelist,axis=0)
            print (" -> Average rotation angle for {}: alpha={}, beta={}".format(inst,meanrotangle[0],meanrotangle[1]))
    print ("----------------------------------------------------------")
    print ("##########################################################")
    return rotangledict


def create_rotation_sql(rotangledict, config={}):

    vainstlist = config.get('vainstlist')
    year = config.get('year')
    rotation = False
    meanrotangle = 0.0
    sqlstatement = []
    print ("IMPORTANT: update database with rotation")
    print ("----------------------------------------")
    for vainst in vainstlist:
        # get existing rotangle data
        header = db.fields_to_dict(db,vainst)
        exist = header.get('DataRotationAlpha','')
        existbeta = header.get('DataRotationBeta','')
        # obtain new
        rotanglelist = rotangledict.get(vainst,[])
        meanrotangle = np.median(rotanglelist,axis=0)

        if not exist == '':
            val = '{},{}_{:.3f}'.format(exist,year,meanrotangle[0])
        else:
            val = '{}_{:.3f}'.format(year,meanrotangle[0])
        updatestr = "UPDATE DATAINFO SET DataRotationAlpha='{}' WHERE SensorID LIKE '{}%';".format(val,vainst[:-5])
        sqlstatement.append(updatestr)
        print (updatestr)
        if not existbeta == '':
            val = '{},{}_{:.3f}'.format(existbeta,year,meanrotangle[1])
        else:
            val = '{}_{:.3f}'.format(year,meanrotangle[1])
        updatestr = "UPDATE DATAINFO SET DataRotationBeta='{}' WHERE SensorID LIKE '{}%';".format(val,vainst[:-5])
        sqlstatement.append(updatestr)
        print (updatestr)
    print ("----------------------------------------")



def scalarcorr(runmode, config={}, startmonth=-1, endmonth=13, skipsec=False):
    print (" ----------------------------------------- ")
    print (" --- Checking and Filtering F --- ")
    print (" ----------------------------------------- ")
    ### !! Run from -1 to 13 to cover the time range of abolutes:
    year = config.get('year')
    scinstlist = config.get('scinstlist')
    testdate = config.get('testdate',"")

    sourcepath = os.path.join(config.get('base'), 'archive', config.get('obscode'))
    db = config.get('primaryDB')
    outpath = config.get('outpath',"/tmp")

    if runmode == 'secondrun':
        scinstlist.append("{}_0001".format(config.get('mobileinst')))

    #### If a testdate is provided (single day)
    tdate = None
    if testdate:
        #extract date and month
        tdate = datetime.strptime(testdate,"%Y-%m-%d")
        if not tdate.year == year:
            print ("Year not fitting - ignoring testdate")
            tdate = None
        else:
            startmonth = tdate.month-1
            endmonth = tdate.month

    f, dt = [],[]
    for i in range(startmonth,endmonth):
        # Extract time range (monthly junks)
        startyear = year
        nextyear = year
        month = str(i+1).zfill(2)
        if i == -1:
           startyear = year-1
           month = str(i+13).zfill(2)
        if i+1 >= 13:
            startyear = year+1
            month = str(i-11).zfill(2)
        nextmonth = str(i+2).zfill(2)
        if i+2 >= 13:
            nextyear = year+1
            nextmonth = str(i-10).zfill(2)

        for scinst in scinstlist:
            print ("-------------------------------------")
            print ("Running analysis for {}".format(scinst))
            print ("-------------------------------------")
            print ("Using Scalar data from path: {}".format(os.path.join(sourcepath,scinst[:-5],scinst,'*')))

            if not tdate:
                dstarttime=datetime.strptime(str(startyear)+'-'+month+'-01',"%Y-%m-%d")
                dendtime=datetime.strptime(str(nextyear)+'-'+nextmonth+'-01',"%Y-%m-%d")
            else:
                dstarttime=tdate
                dendtime=tdate+timedelta(days=1)
            print ("Dealing with data between {} and {}".format(dstarttime,dendtime))

            try:
                sc = read(os.path.join(sourcepath,scinst[:-5],scinst,'*'),starttime=dstarttime,endtime=dendtime)
                # get header from db
                print ("Obtained {} data points".format(sc.length()[0]))
                # 2) Remove duplicates
                print ("Removing duplicates")
                bef = sc.length()[0]
                sc = sc.removeduplicates()
                aft = sc.length()[0]
                print (" -> dropped {} duplicate values".format(bef-aft))
                if sc.length()[0] > 1:
                    print ("Getting gaps and data base meta info:")
                    sc = sc.get_gaps()
                    sc.header = db.fields_to_dict(db,scinst)
                    # flag it
                    print ("Flagging with existing flags:")
                    print ("a) from DB:")
                    flaglist = db.flags_from_db(scinst[:-5], begin=dstarttime, end=dendtime) #data.header['SensorID'])
                    print ("   Length of DB flaglist: {}".format(len(flaglist)))
                    print ("b) from file:")
                    fileflaglist = flagging.load(os.path.join(outpath,'magpy',scinst[:-5]+'_flags.json'), sensorid=sc.header['SensorID'], begin=dstarttime, end=dendtime)
                    print("Loaded {} flags from file in this time range".format(len(fileflaglist)))
                    if len(flaglist) > 0 and len(fileflaglist) > 0:
                        flaglist = flaglist.join(fileflaglist)
                    elif not len(flaglist) > 0:
                        flaglist = fileflaglist
                    print("Found a sum of {} flags".format(len(flaglist)))
                    sc.header["DataFlags"] = flaglist
                    print ("Applying offsets and timeshifts")
                    sc = sc.apply_deltas()
                    print (" -> final length: {}".format(sc.length()[0]))
                    sc = sc.removeduplicates()
                    print (" -> final length after dupliacte removal: {}".format(sc.length()[0]))
                    if not runmode=='firstrun' and not skipsec:
                        hsc = sc.copy()
                        print ("Drop all columns except f and comments for high resolution storage")
                        for el in KEYLIST:
                            if not el in ['time','f','flag','comment']:
                                hsc = hsc._drop_column(el)
                        #print ("Resample to one second")   # Done in scalarcomb  -> resample deletes flags
                        #hsc = hsc.resample(['f','flag','comment'],period=1)
                        print ("Write monthly high resolution file with full info (length {}".format(hsc.length()[0]))
                        fname = '{}_scalar_oc_sec_{}'.format(scinst,runmode)
                        hsc.write(os.path.join(outpath,'magpy'),filenamebegins=fname,dateformat='%Y%m',coverage='month',mode='replace',format_type='PYCDF')
                    print ("Removing flagged data before filtering")
                    sc = flaglist.apply_flags(sc, mode='drop')
                    print ("Filtering")
                    sc = sc.filter(missingdata='mean')
                    print ("Fill gaps with nan")
                    sc = sc.get_gaps()
                    for el in KEYLIST:
                        if not el in ['time','f']:
                            sc = sc._drop_column(el)
                    #mp.plot(sc)
                    print ("Writing data")
                    fminname = '{}_scalar_oc_min_{}_{}'.format(scinst,runmode,year)
                    sc.write(os.path.join(outpath,'magpy'),filenamebegins=fminname,dateformat='%Y',coverage='all',mode='replace',format_type='PYCDF')
            except:
                pass

class TestDefinitive(unittest.TestCase):
    """
    Test environment for all methods
    """

    def test_variocorr(self):
        runmode ="firstrun"
        config = mm.get_conf(os.path.join('..', 'conf', 'basevalue.cfg'))
        config['dbcredentials'] = "cobsdb"
        startdate, enddate = None, "2025-12-31"
        varios, scalars, piers = ["LEMI036_1_0002_0002"],["GP20S3NSS2_012201_0001_0001"],["A2"]
        config = basevalue.check_conf(config, startdate, enddate, varios=varios, scalars=scalars, piers=piers, debug=True)
        config['blvdatapath'] = "/tmp"
        config['base'] = os.path.abspath("../test")
        config['obscode'] = "WIC"
        config['didatapath'] = os.path.abspath("../test/archive/WIC/DI/analyze")
        config['blvabb'] = "BLV"
        print (config)
        rotangledict = variocorr(runmode, config=config, startmonth=0, endmonth=12, skipsec=False, debug=True)
        print ("RES", rotangledict)
        self.assertTrue(rotangledict)


if __name__ == "__main__":
    unittest.main(verbosity=2)